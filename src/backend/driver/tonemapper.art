fn @make_byte_color(c : Color) = make_packed_color(
    (clampf(c.r, 0, 1) * 255) as u8,
    (clampf(c.g, 0, 1) * 255) as u8,
    (clampf(c.b, 0, 1) * 255) as u8,
    (clampf(c.a, 0, 1) * 255) as u8
);

fn @make_packed_color(r: u8, g: u8, b: u8, a: u8) = ((a as u32) << 24) | ((r as u32) << 16) | ((g as u32) << 8) | (b as u32);

#[export]
fn ig_utility_imageinfo(device_id: i32, in_pixels: &[f32], width: i32, height: i32, settings: &ImageInfoSettings, output: &mut ImageInfoOutput) {
    let device = @get_device(device_id);

    let size  = width * height;
    let scale = settings.scale;

    let buffer_in = device.make_buffer(in_pixels as &[u8], size * 3);
    let get_elem  = @|i:i32| srgb_to_xyY(color_mulf(make_color(buffer_in.load_f32(i * 3 + 0), buffer_in.load_f32(i * 3 + 1), buffer_in.load_f32(i * 3 + 2), 1), scale)).b; // Only luminance

    output.min = device.parallel_reduce_f32(size, get_elem, @|a, b| math_builtins::fmin(a, b));
    output.max = device.parallel_reduce_f32(size, get_elem, @|a, b| math_builtins::fmax(a, b));
    output.avg = device.parallel_reduce_f32(size, get_elem, @|a, b| a + b) / size as f32;

    let global_data = device.request_buffer("__imageinfo_percentile", sizeof[f32]() as i32 * 4 , 0);
    global_data.store_i32_host(0, bitcast[i32](flt_max));
    global_data.store_i32_host(1, 0);
    global_data.store_i32_host(2, 0);

    // Window based percentile setup (which is just approximative)
    let median_factor = safe_div(1, ((width - 2) * (height - 2)) as f32);
    for (x, y) in device.parallel_range_2d(1, width - 1, 1, height - 1) {
        // First get the window information
        let mut window : [f32 * 9];
        for i in unroll(0, 3) {
            for j in unroll(0, 3) {
                let ind = (y+i-1) * width + (x+j-1);
                window(i*3+j) = @get_elem(ind);
            }
        }
        
        // Sort the window
        batcher_sort(9, @|i, j| {
            if window(i) > window(j) {
                let a = window(i);
                window(i) = window(j);
                window(j) = a;
            }
        });

        // Put percentile information
        let soft_min = window(1);
        let soft_max = window(7);
        let median   = window(4);

        if soft_min >= 0 { global_data.min_atomic_i32(0, bitcast[i32](soft_min)); }
        if soft_max >= 0 { global_data.max_atomic_i32(1, bitcast[i32](soft_max)); }
        if median   >= 0 { global_data.add_atomic_f32(2, median * median_factor); }
    }
    device.sync();

    output.soft_min = bitcast[f32](global_data.load_i32_host(0));
    output.soft_max = bitcast[f32](global_data.load_i32_host(1));
    output.median   = bitcast[f32](global_data.load_i32_host(2));

    // Setup histogram
    let histogram_start     = output.soft_min;
    let histogram_end       = output.soft_max;
    let histogram_range     = histogram_end - histogram_start;
    let histogram_bin_count = settings.bins;
    let histogram_factor    = safe_div(histogram_bin_count as f32, histogram_range);

    let dev_hist_size = round_up(histogram_bin_count, 4);
    let dev_histogram = device.request_buffer("__imageinfo_histogram", sizeof[i32]() as i32 * dev_hist_size, 0);

    // Reset histogram
    for i in device.parallel_range(0, dev_hist_size / 4) {
        dev_histogram.store_int4(i * 4, 0, 0, 0, 0);
    }
    device.sync();

    // Update histogram
    for i in device.parallel_range(0, size) {
        let L   = get_elem(i);
        let bin = clamp(((L - histogram_start) * histogram_factor) as i32, 0, histogram_bin_count - 1);
        dev_histogram.add_atomic_i32(bin, 1);
    }
    device.sync();

    // Copy histogram to host
    dev_histogram.copy_to_host(0, histogram_bin_count, settings.histogram);
    device.sync();
}

#[export]
fn ig_utility_tonemap(device_id: i32, in_pixels: &[f32], out_pixels: &mut [u32], width: i32, height: i32, settings: &TonemapSettings) -> () {
    let device = @get_device(device_id);

    let buffer_in  = device.make_buffer(in_pixels as &[u8],  width * height * 3);
    let buffer_out = device.make_buffer(out_pixels as &[u8], width * height);

    let use_gamma       = settings.use_gamma;
    let scale           = settings.scale;
    let exposure_factor = settings.exposure_factor;
    let exposure_offset = settings.exposure_offset;
    
    fn @tonemap(method: i32) -> () {
        for ind in device.parallel_range(0, width * height) {
            // TODO: It would be more load friendly if the image buffer was actually 4 units per component, instead of 3
            let rgb = color_mulf(make_color(buffer_in.load_f32(ind * 3 + 0), buffer_in.load_f32(ind * 3 + 1), buffer_in.load_f32(ind * 3 + 2), 1), scale);
            let xyY = srgb_to_xyY(rgb);
    
            if math_builtins::isnan(xyY.b) {
                buffer_out.store_i32(ind, bitcast[i32](make_packed_color(0, 255, 255, 255))); // Cyan
            } else if !math_builtins::isfinite(xyY.b) {
                buffer_out.store_i32(ind, bitcast[i32](make_packed_color(255, 0, 150, 255))); // Pink
            } else if xyY.r < 0.0 || xyY.g < 0.0 || xyY.b < 0.0 {
                buffer_out.store_i32(ind, bitcast[i32](make_packed_color(255, 255, 0, 255))); // Orange
            } else {
                let L = exposure_factor * xyY.b + exposure_offset;
                //let scale1 = bitcast[f32](1 / (kernel_size * kernel_size));
                

                let nL = match method {
                    0 => L,
                    1 => reinhard(L),
                    2 => reinhard_modified(L),
                    _ => aces(L)
                };
    
                let color = xyY_to_srgb(make_color(xyY.r, xyY.g, nL, 1));
                
                let out_color = if use_gamma {
                    color_mulf(make_color(srgb_gamma(color.r),
                        srgb_gamma(color.g),
                        srgb_gamma(color.b),
                        color.a),1)
                } else { 
                    color
                };
    
                buffer_out.store_i32(ind, bitcast[i32](make_byte_color(out_color)));
            }
        }
    }

    // Force expansion of the actual methods
    match settings.method {
        0 => tonemap(0),
        1 => tonemap(1),
        2 => tonemap(2),
        _ => tonemap(3)
    };
    
    device.present();
    device.sync();
}

fn distance(x : i32, y : i32, i : i32, j : i32) = math_builtins::sqrt((x - i) * (x - i) + (y - j) * (y - j)) as f32;

// // Need to change exp = 2.718 to something more accurate if possible
fn gaussian(x : f32, sigma : f32) -> f32{
    // let ind : f32 = x as f32;
    let abs_x = x;//math_builtins::fabs(x);
    let norm = (1.0 / (2 * flt_pi * (sigma * sigma))); ////(math_builtins::sqrt(2 * flt_pi) * sigma)
    let expo = -1.0 * (abs_x * abs_x) / (2.0 * sigma * sigma);
    let result = norm * math_builtins::exp(expo);
    result
}

fn compute_luminance_weight(lp : f32, lq : f32, variance : f32, sigma_c : f32) -> f32{
    let diff = lp - lq;
    let distance = math_builtins::fabs(diff);
    let eval = -distance / (math_builtins::sqrt(variance) * sigma_c + 1e-6);
    let weight = math_builtins::exp(eval);
    weight
}

fn compute_normal_depth_weight(n_p : Vec3, n_q : Vec3, sigma : f32) -> f32{
    // same function for both weights- inputs differ
    let diff = vec3_sub(n_p, n_q);
    let distance = vec3_len(diff);
    let eval = -distance / (sigma + 1e-6);
    let weight = math_builtins::fmin(1.0 as f32, math_builtins::exp(eval));
    weight
}

fn get_pixel_value(ind_q : i32, buffer : DeviceBuffer, width : i32, height : i32) -> f32{
    // for border handling
    // ind_p - center pixel, ind_q - neighbour
    // let value = 0.0 as f32;//frame_buffer.load_f32(ind_q);
    // value
    if((ind_q >= 0) && (ind_q <= (width) * (height) * 3 + 1)){
        // right border
        // if((ind_p+1) % width == 0) && (ind_q > ind_p)
        let val = buffer.load_f32(ind_q);
        if(!math_builtins::isnan(val)){val}
        else{0.0 as f32}
    }
    else{0.0 as f32}

    // buffer.load_f32(ind_q)
}

fn get_vector_from_buffer(ind : i32, buffer : DeviceBuffer, width : i32, height : i32) -> Vec3{
    // for border handling
    // ind_p - center pixel, ind_q - neighbour

    // takes care of right and left borders too
    if((ind >= 0) && (ind <= (width) * (height) * 3 + 1)){
        if((ind) % 3 == 0){
            let nx = buffer.load_f32(ind);
            let ny = buffer.load_f32(ind + 1);
            let nz = buffer.load_f32(ind + 2);
            make_vec3(nx, ny, nz)
        }
        else if((ind) % 3 == 1){
            let nx = buffer.load_f32(ind - 1);
            let ny = buffer.load_f32(ind);
            let nz = buffer.load_f32(ind + 1);
            make_vec3(nx, ny, nz)
        }
        else{
            let nx = buffer.load_f32(ind - 2);
            let ny = buffer.load_f32(ind - 1);
            let nz = buffer.load_f32(ind);
            make_vec3(nx, ny, nz)
        }
    }
    else{
        make_vec3(0.0, 0.0, 0.0)
    }
}

fn isReprjValid(width : i32, height : i32, prev_coord : i32, curr_normal : Vec3, prev_normal : Vec3, curr_depth : Vec3, prev_depth : Vec3) -> bool {
    // let p = curr_coord.x + curr_coord.y * width * 3;
    // let q = prev_coord.x + prev_coord.y * width * 3;
    // check if the pixel is inside the screen
    if((prev_coord < 0) || (prev_coord > (width * height * 3))){
        return(false)
    }

    // // check deviation in depth
    let diff_depth = vec3_sub(prev_depth, curr_depth);
    let distance_depth = vec3_len(diff_depth);
    if(distance_depth > (0.1 as f32)){
        return(false)
    }

    // // check deviation in normal
    let diff_normal = vec3_sub(prev_normal, curr_normal);
    let distance_normal = vec3_len(diff_normal);
    if(distance_normal > (0.1 as f32)){
        return(false)
    }

    true
}

// fn BackProjection(){

// }
struct GbufferTexel{
    normal : Vec3,
    position : Vec3,
    albedo : Vec3,
    geomId : i32,
} // not feasible for entire buffers ???



#[export]
fn ig_utility_filter(device_id: i32, in_pixels: &[f32], normals: &[f32], depth: &[f32], albedo: &[f32], luminance: &[f32], width: i32, height: i32) -> () {
    let device = @get_device(device_id);

    // Computing buffers
    // in_pixels - pointer to frame_buffer
    let buffer_out = device.make_buffer(in_pixels as &[u8],  width * height * 3); 
    let buffer_n = device.make_buffer(normals as &[u8], width * height * 3);
    let buffer_d = device.make_buffer(depth as &[u8], width * height * 3);
    let buffer_a = device.make_buffer(albedo as &[u8], width * height * 3);
    let buffer_l = device.make_buffer(luminance as &[u8], width * height * 3);

    // bunch of buffers for storing intermediates
    let buffer_in = device.request_buffer("__input_buffer", width * height * 3, 0); //c_(i)
    let history_buffer = device.request_buffer("__history_buffer", width * height * 3, 0); //c_(i+1)
    let detail_buffer = device.request_buffer("__reconstruction_buffer", width * height * 3, 0);
    let buffer_normals = device.request_buffer("__normals_buffer", width * height * 3, 0);
    let buffer_depth = device.request_buffer("__depth_buffer", width * height * 3, 0);
    let buffer_albedo = device.request_buffer("__albedo_buffer", width * height * 3, 0);
    let buffer_lum = device.request_buffer("__luminance_buffer", width * height * 3, 0);
    
    // intializing buffer_values as 0 (dont know if necessary but to be safe)
    for ind in device.parallel_range(0, (width-1) * (height-1) * 3) {
        buffer_in.store_i32(ind, bitcast[i32](0.0));
        history_buffer.store_i32(ind, bitcast[i32](0.0));
        detail_buffer.store_i32(ind, bitcast[i32](0.0));
        buffer_albedo.store_i32(ind, bitcast[i32](0.0));
        buffer_lum.store_i32(ind, bitcast[i32](0.0));
    }
    device.sync();

    for ind in device.parallel_range(0, (width) * (height) * 3 + 1) {
        let out = get_pixel_value(ind, buffer_out, width, height);// buffer_out.load_f32(ind);
        buffer_in.store_i32(ind, bitcast[i32](out));
        let norml = get_pixel_value(ind, buffer_n, width, height);//buffer_n.load_f32(ind);
        buffer_normals.store_i32(ind, bitcast[i32](norml));
        
        let dep = get_pixel_value(ind, buffer_d, width, height);//buffer_d.load_f32(ind);
        buffer_depth.store_i32(ind, bitcast[i32](dep));
        let alb = get_pixel_value(ind, buffer_a, width, height);//buffer_a.load_f32(ind);
        // if(alb >= 0.1){
        //     let demodulate = alb;
        //     let lum = out / demodulate;
        //     buffer_lum.store_i32(ind, bitcast[i32](lum));}
        // else{
        //     let demodulate = 1.0 as f32;
        //     let lum = out / demodulate;
        //     buffer_lum.store_i32(ind, bitcast[i32](lum));
        // }
        let lum = get_pixel_value(ind, buffer_l, width, height);//buffer_l.load_f32(ind);
        // let illuminance = math_builtins::fmax(0.0 as f32, (out - lum));//math_builtins::fmax(0.01 as f32, alb);
        let illuminance = math_builtins::fabs((out - lum));// / math_builtins::fmax(1.0 as f32, alb);
        buffer_lum.store_i32(ind, bitcast[i32](illuminance));
    }
    device.sync();

    ///////// calculating luminance buffer
    for ind in device.parallel_range(0, (width-1) * (height-1) * 3) {
        let rgb = get_vector_from_buffer(ind, buffer_in, width, height);
        let color = make_color(rgb.x, rgb.y, rgb.z, 1);
        let lum_val = color_luminance(color);
        buffer_lum.store_i32(ind, bitcast[i32](lum_val));
    }
    /////////

    ///////// variance computation (DONE)(NEED to check Buffer)

    // 2x2 kernel
    // let ent1 = make_vec2((1.0 / 4.0) as f32, (1.0 / 8.0) as f32);
    // let ent2 = make_vec2((1.0 / 8.0) as f32, (1.0 / 16.0) as f32);
    // let kernel = make_mat2x2(ent1, ent2);

    let col1 = make_vec3(1.0 / 16.0 as f32, 1.0 / 8.0 as f32, 1.0 / 16.0 as f32);
    let col2 = make_vec3(1.0 / 8.0 as f32,  1.0 / 4.0 as f32, 1.0 / 8.0 as f32);
    let gaussian_kernel = make_mat3x3(col1, col2, col1);

    // let gaussian_kernel = [1.0 / 16.0 as f32, 1.0 / 8.0 as f32, 1.0 / 16.0 as f32,
    //                     1.0 / 8.0 as f32,  1.0 / 4.0 as f32, 1.0 / 8.0 as f32,
    //                     1.0 / 16.0 as f32, 1.0 / 8.0 as f32, 1.0 / 16.0 as f32];
    
    let mut variance_sum_w : f32;
    let mut variance_add : f32;
    variance_sum_w = 0.0 as f32;
    variance_add = 0.0;

    // let kernel_ind = [make_vec2(-1, -1), make_vec2(0, -1), make_vec2(1, -1),
    //                 make_vec2(-1, 0), make_vec2(0, 0), make_vec2(1, 0),
    //                 make_vec2(-1, 1), make_vec2(0, 1), make_vec2(1, 1)];

    let variance_buffer = device.request_buffer("__variance_buffer", width * height * 3, 0);
    
    // variance computed using a 3x3 gaussian kernel centered around center pixel(pos)
    let up_var = 1;
    for ind in unroll(0, (width-1) * (height-1) * 3) {
        for j in unroll(up_var * -1, up_var + 1){ // yy
            let row = ind + width * 3 * j;
            for i in unroll(up_var * -1, up_var + 1){ // xx
                let k = mat3x3_at(gaussian_kernel, abs(i), abs(j));
                let val = get_pixel_value(row + j * 3, buffer_in, width, height); // dont know if buffer_in(aka frambuffer is the correct buffer)
                variance_add += val * k;
                variance_sum_w += k;
            }
        }
        let var = math_builtins::fmax(variance_add / variance_sum_w, 0.0 as f32);
        variance_buffer.store_i32(ind, bitcast[i32](var));
    }
    ///////////

    ///////////////
    let num_levels = 0;
    
    // Settings for filter
    let sigma_i = 10.0 as f32; // for gaussian filter

    // initial setting
    // let sigma_rt = 1.0 as f32;
    // let sigma_normal = 2.0 as f32;
    // let sigma_d = 1.0 as f32;
    let kernel_size = 5; //(2 * (4 * sigma_i + 0.5) + 1) as i32;

    // settings 1 based on cuda_denoising //default setting
    let sigma_l = 0.7 as f32;
    let sigma_d = 1 as f32;//0.35 as f32; //ui_sigmax
    let sigma_normal = 128 as f32;//0.2 as f32;

    //settings 2 based on cuda_denoising
    // let sigma_l = 0.45 as f32;
    // let sigma_d = 0.35 as f32; //ui_sigmax
    // let sigma_normal = 0.2 as f32;

    // 5x5 A-Trous kernel
    let h = [1.0 / 256.0, 1.0 / 64.0, 3.0 / 128.0, 1.0 / 64.0, 1.0 / 256.0,
        1.0 / 64.0, 1.0 / 16.0, 3.0 / 32.0, 1.0 / 16.0, 1.0 / 64.0,
        3.0 / 128.0, 3.0 / 32.0, 9.0 / 64.0, 3.0 / 32.0, 3.0 / 128.0,
        1.0 / 64.0, 1.0 / 16.0, 3.0 / 32.0, 1.0 / 16.0, 1.0 / 64.0,
        1.0 / 256.0, 1.0 / 64.0, 3.0 / 128.0, 1.0 / 64.0, 1.0 / 256.0 ];
    
    let kernel_weights = [1.0 as f32, 2.0/3.0 as f32, 1.0/6.0 as f32];
    let mut sum_w : f32; // weights sum
    let mut add : f32; // color sum
    let mut variance_sum : f32;
    let mut sqrd_sum_w : f32; // for variance
    
    let up = ((kernel_size - 1) / 2);
    
    for stride in unroll(1, num_levels+2){
        for ind in unroll(0, (width-1) * (height-1) * 3) {
            // pixel no. 1,2,3 -> 1.r,1.g,1.b,2.r,2.g,2.b,3.r,3.g,3.b
            // arranged in serial order
            add = 0;
            sum_w = 0.0;
            variance_sum = 0.0;
            sqrd_sum_w = 0.0;

            // 1D kernel
            // for i in unroll (kernel_size * -1, kernel_size+1){
            //     add += buffer_in.load_f32(ind + i * 3);
            // }
            let lp = get_pixel_value(ind, buffer_lum, width, height); // luminance
            let pp = get_vector_from_buffer(ind, buffer_depth, width, height); //position
            let np = get_vector_from_buffer(ind, buffer_normals, width, height); //normal
            let variance_p = get_pixel_value(ind, variance_buffer, width, height);
            
            for i in unroll (up * -1, up + 1){
                let row = ind + stride * width * 3 * i;
                for j in unroll (up * -1, up + 1){
                    let q = row + stride * j * 3; //neighbour
                    let dist = (i * i + j * j) as f32;
                    let w_s = gaussian(dist, sigma_i);
                    // let kernel = w_s;
                    // new weights based on cuda_denoiser
                    let lq = get_pixel_value(q, buffer_lum, width, height);
                    let pq = get_vector_from_buffer(q, buffer_depth, width, height);
                    let nq = get_vector_from_buffer(q, buffer_normals, width, height);

                    // edge stopping weights
                    let wl = compute_luminance_weight(lp, lq, variance_p, sigma_l);
                    let wn = compute_normal_depth_weight(np, nq, sigma_normal);
                    let wd = compute_normal_depth_weight(pp, pq, sigma_d);

                    // filter weights
                    let k = (up + i) + (up + j) * kernel_size; // index to sample from h(the atrous kernel)
                    let weight = (h(k) as f32) * wn * wd;// * wl; // check luminance buffer
                    sum_w += weight;
                    sqrd_sum_w += weight * weight;
                    let buf_value = get_pixel_value(q, buffer_in, width, height);
                    add += (buf_value * weight);

                    let variance_q = get_pixel_value(q, variance_buffer, width, height);
                    variance_sum += (variance_q * weight * weight);
                }
            }
            // update color and variance

            // if(sum_w > 10e-6){
            //     let out = add / sum_w;
            //     history_buffer.store_i32(ind, bitcast[i32](out)); // convolved result / final convolution that needs to be added at iteration N 
            //     let var_update = variance_sum / sqrd_sum_w;
            //     variance_buffer.store_i32(ind, bitcast[i32](var_update));
            // }
            // else{
            //     let out = buffer_in.load_f32(ind);
            //     history_buffer.store_i32(ind, bitcast[i32](out));
            // }
            let out = add / sum_w;
            history_buffer.store_i32(ind, bitcast[i32](out)); // convolved result / final convolution that needs to be added at iteration N 
            let var_update = variance_sum / sqrd_sum_w;
            variance_buffer.store_i32(ind, bitcast[i32](var_update));
            // let out = add / sum_w;
            // history_buffer.store_i32(ind, bitcast[i32](out)); // convolved result / final convolution that needs to be added at iteration N          
            // let detail_current = out - buffer_in.load_f32(ind);
            // detail_buffer.store_i32(ind, bitcast[i32](detail_current));
            // if(stride < num_levels+1){
            //     let detail_prev = detail_buffer.load_f32(ind);
            //     let detail_current = out - buffer_in.load_f32(ind);
            //     detail_buffer.store_i32(ind, bitcast[i32](math_builtins::fabs(detail_prev + detail_current))); // detail layer of wavelet transform added with prev_detail for reconstruction
            // }
            // else{
            //     let detail_prev = detail_buffer.load_f32(ind);
            //     let final_conv = history_buffer.load_f32(ind);

            //     detail_buffer.store_i32(ind, bitcast[i32](math_builtins::fabs(detail_prev + final_conv)));
            // }
        }
        device.sync();

        for ind in device.parallel_range(0, (width-1) * (height-1) * 3) {
            let out = history_buffer.load_f32(ind);
            // buffer_in.store_i32(ind, bitcast[i32](out));
            buffer_lum.store_i32(ind, bitcast[i32](out));
        }
        // device.present();
        device.sync();
    }
    // writing to output- framebuffer
    for ind in device.parallel_range(0, (width-1) * (height-1) * 3) {
        let out = detail_buffer.load_f32(ind);
        let org = buffer_in.load_f32(ind);
        let albedo = buffer_a.load_f32(ind);
        let norml = get_pixel_value(ind, buffer_n, width, height);
        // let lum = buffer_lum.load_f32(ind);
        let lum_from_path = get_pixel_value(ind, buffer_l, width, height);
        let depth = buffer_depth.load_f32(ind); //probably works
        let lum = get_pixel_value(ind, buffer_lum, width, height);

        let cuda_out = history_buffer.load_f32(ind);
        buffer_out.store_i32(ind, bitcast[i32](cuda_out)); //math_builtins::fabs(org)
    }

    device.present();
    device.sync();
}
